{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding MONAI Datasets, Caching, and Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users often need to train the model with many (potentially thousands of) epochs over the data to achieve the desired model quality. A native PyTorch implementation may repeatedly load data and run the same preprocessing steps for every epoch during training, which can be time-consuming and unnecessary, especially when the medical image volumes are large.  By utilizing Dataset Caching, you can reduce the amount of time your system takes to load this data and preprocess it, reducing your overall training time.\n",
    "\n",
    "Network functionality represents a significant design opportunity for MONAI. Pytorch is very much unopinionated in how networks are defined. It provides Module as a base class to create a network and a few methods that must be implemented. Still, there is no prescribed pattern nor much helper functionality for initializing networks.\n",
    "\n",
    "The lack of helper functionality leaves a lot of room for defining some beneficial 'best practice' patterns for constructing new networks in MONAI. Although trivial, inflexible network implementations are easy enough, but we can give users a toolset that makes it much easier to build well-engineered, flexible networks and demonstrate their value by committing to use them in the networks that we build.\n",
    "\n",
    "## MONAI Datasets, Caching, and Networks\n",
    "\n",
    "To help you understand more about MONAI Datasets and Caching options, this guide will help you answer five key questions:\n",
    "\n",
    "1. **What is a MONAI Dataset?**\n",
    "2. **What is Dataset Caching and how do I use it?**\n",
    "3. **What common datasets are provided by MONAI?**\n",
    "4. **How do you use MONAI Layers?**\n",
    "5. **How do you use these flexible layers to create a network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's get started by importing our dependencies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.data import Dataset, DataLoader, CacheDataset, PersistentDataset, SmartCacheDataset, ZipDataset\n",
    "from monai.apps import DecathlonDataset\n",
    "from monai.transforms import (\n",
    "    MapTransform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. What is a MONAI Dataset?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MONAI Dataset is a generic dataset with a __len__ property, __getitem__ property, and an optional callable data transform when fetching a data sample.\n",
    "\n",
    "We'll start by initializing some generic data, calling the Dataset class with the generic data, and specifying None for our transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [{\"data\": 4}, \n",
    "         {\"data\": 9}, \n",
    "         {\"data\": 3}, \n",
    "         {\"data\": 7}, \n",
    "         {\"data\": 1},\n",
    "         {\"data\": 2},\n",
    "         {\"data\": 5}]\n",
    "dataset = monai.data.Dataset(items, transform=None)\n",
    "\n",
    "print(f\"Length of dataset is {len(dataset)}\")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compatible with the PyTorch DataLoader\n",
    "\n",
    "MONAI functionality should be compatible with the PyTorch DataLoader, although free to subclass from it if there is additional functionality that we consider key, which cannot be realized with the standard DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in torch.utils.data.DataLoader(dataset, batch_size=2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load items with a customized transform\n",
    "\n",
    "We'll create a custom transform called `SquareIt`, which will replace the corresponding value of the input's `keys` with a squared value. In our case, `SquareIt(keys='data')` will apply the square transform to the value of `x['data']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareIt(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        MapTransform.__init__(self, keys)\n",
    "        print(f\"keys to square it: {self.keys}\")\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        key = self.keys[0]\n",
    "        data = x[key]\n",
    "        output = {key: data ** 2}\n",
    "        return output\n",
    "\n",
    "square_dataset = Dataset(items, transform=SquareIt(keys='data'))\n",
    "for item in square_dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. What is Dataset Caching and how do I use it?**\n",
    "\n",
    " MONAI provides multi-thread versions of `CacheDataset` and `LMDBDataset` to accelerate these transformation steps during training by storing the intermediate outcomes before the first randomized transform in the transform chain. Enabling this feature could potentially give 10x training speedups in the Datasets experiment.\n",
    " \n",
    "<img src=\"cache_dataset.png\" style=\"width: 700px;\"/>\n",
    " \n",
    "To demonstrate the benefit dataset caching, we're going to construct a dataset with a slow transform.  To do that, we're going to call the sleep function during each of the `__call__` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowSquare(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        MapTransform.__init__(self, keys)\n",
    "        print(f\"keys to square it: {self.keys}\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        time.sleep(1.0)\n",
    "        output = {key: x[key] ** 2 for key in self.keys}\n",
    "        return output\n",
    "\n",
    "square_dataset = Dataset(items, transform=SlowSquare(keys='data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it's going to take about 7 seconds to go through all the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for item in square_dataset: print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we run this loop we're going to get roughly 7 seconds to go through all of the items.  If you were do this for 100 epochs, you're adding almost 12 extra minutes of load time to your total training loop.  Let's look at ways that we can improve this time by utilizing caching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Dataset\n",
    "\n",
    "When using [CacheDataset](https://docs.monai.io/en/latest/data.html?highlight=dataset#cachedataset) the caching is done when the object is initialized for the first time, so the initialization is slower than a regular dataset.\n",
    "\n",
    "By caching the results of non-random preprocessing transforms, it accelerates the training data pipeline. If the requested data is not in the cache, all transforms will run normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_cached = CacheDataset(items, transform=SlowSquare(keys='data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, repeatedly fetching the items from an initialized CacheDataset is fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit list(item for item in square_cached)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistent Caching\n",
    "\n",
    "[PersistantDataset](https://docs.monai.io/en/latest/data.html?highlight=dataset#persistentdataset) allows for persistent storage of pre-computed values to efficiently manage larger than memory dictionary format data.\n",
    "\n",
    "The non-random transform components are computed when first used and stored in the cache_dir for rapid retrieval on subsequent uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_persist = monai.data.PersistentDataset(items, transform=SlowSquare(keys='data'), cache_dir=\"my_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time for item in square_persist: print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the initialization of the PersistentDataset we passed in the parameter \"my_cache\" for the location to store the intermediate data. We'll look at that directory below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls my_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling out to the dataset on the following epochs, it will not call the slow transform but used the cached data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [item for item in square_persist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fresh dataset instances can make use of the caching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_persist_1 = monai.data.PersistentDataset(items, transform=SlowSquare(keys='data'), cache_dir=\"my_cache\")\n",
    "%timeit [item for item in square_persist_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching in action\n",
    "- There's also a [SmartCacheDataset](https://docs.monai.io/en/latest/data.html#monai.data.SmartCacheDataset) to hide the transforms latency with less memory consumption.\n",
    "- The dataset tutorial notebook has a working example and a comparison of different caching mechanism in MONAI: https://github.com/Project-MONAI/tutorials/blob/master/acceleration/dataset_type_performance.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"datasets_speed.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. What common datasets are provided by MONAI?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly get started with popular training data in the medical domain, MONAI provides several data-specific Datasets(like: MedNISTDataset, DecathlonDataset, etc.), which include downloading from our AWS storage, extracting data files and support generation of training/evaluation items with transforms.\n",
    "\n",
    "The [DecathlonDataset](https://docs.monai.io/en/latest/data.html?highlight=dataset#decathlon-datalist) function leverages the features described throughout this notebook.  These datasets are an extension of CacheDataset covered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = monai.apps.DecathlonDataset(root_dir=\"./\", task=\"Task09_Spleen\", section=\"training\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.get_properties(\"numTraining\"))\n",
    "print(dataset.get_properties(\"description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0]['image'].shape)\n",
    "print(dataset[0]['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. How do you use MONAI Layers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.layers import Conv, Act, split_args, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution as an example\n",
    "\n",
    "The [Conv](https://docs.monai.io/en/latest/networks.html#convolution) class has two options for the first argument. The second argument must be the number of spatial dimensions, `Conv[name, dimension]`, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Conv[Conv.CONV, 1])\n",
    "print(Conv[Conv.CONV, 2])\n",
    "print(Conv[Conv.CONV, 3])\n",
    "print(Conv[Conv.CONVTRANS, 1])\n",
    "print(Conv[Conv.CONVTRANS, 2])\n",
    "print(Conv[Conv.CONVTRANS, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configured classes are the \"vanilla\" PyTorch layers. We could create instances of them by specifying the layer arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
    "Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Act](https://docs.monai.io/en/latest/networks.html#module-monai.networks.layers.Act) classes don't require the spatial dimension information, but supports additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Act[Act.PRELU])\n",
    "Act[Act.PRELU](num_parameters=1, init=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These could be fully specified with a tuple of `(type_name, arg_dict)`, such as `(\"prelu\", {\"num_parameters\": 1, \"init\": 0.1})`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_name, act_args = split_args((\"prelu\", {\"num_parameters\": 1, \"init\": 0.1}))\n",
    "Act[act_name](**act_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. How do you use these flexible layers to create a network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These APIs allow for flexible definitions of networks.  Below we'll create a class called `MyNetwork` that utilizes `Conv`, `Act`, and `Pool`.  Each Network requires an `__init__` and a `forward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(torch.nn.Module):\n",
    "    \n",
    "  def __init__(self, dims=3, in_channels=1, out_channels=8, kernel_size=3, pool_kernel=2, act=\"relu\"):\n",
    "    super(MyNetwork, self).__init__()\n",
    "    # convolution\n",
    "    self.conv = Conv[Conv.CONV, dims](in_channels, out_channels, kernel_size=kernel_size)\n",
    "    # activation\n",
    "    act_type, act_args = split_args(act)\n",
    "    self.act = Act[act_type](**act_args)\n",
    "    # pooling\n",
    "    self.pool = Pool[Pool.MAX, dims](pool_kernel)\n",
    "  \n",
    "  def forward(self, x: torch.Tensor):\n",
    "    x = self.conv(x)\n",
    "    x = self.act(x)\n",
    "    x = self.pool(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network definition can be instantiated to support either 2D or 3D inputs, with flexible kernel sizes.  It becomes handy when adapting the same architecture design for different tasks, switching among 2D, 2.5D, 3D easily.\n",
    "\n",
    "Almost all the MONAI layers, blocks and networks are extensions of `torch.nn.modules` and follow this pattern. This makes the implementations compatible with any PyTorch pipelines and flexible with the network design. The current collections of those differentiable modules are listed in https://docs.monai.io/en/latest/networks.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default network instance\n",
    "default_net = MyNetwork()\n",
    "print(default_net)\n",
    "print(default_net(torch.ones(3, 1, 20, 20, 30)).shape)\n",
    "\n",
    "# 2D network instance\n",
    "elu_net = MyNetwork(dims=2, in_channels=3, act=(\"elu\", {\"inplace\": True}))\n",
    "print(elu_net)\n",
    "print(elu_net(torch.ones(3, 3, 24, 24)).shape)\n",
    "\n",
    "# 3D network instance with anisotropic kernels\n",
    "sigmoid_net = MyNetwork(3, in_channels=4, kernel_size=(3, 3, 1), act=\"sigmoid\")\n",
    "print(sigmoid_net)\n",
    "print(sigmoid_net(torch.ones(3, 4, 30, 30, 5)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MONAI includes over 20 Networks, you can find them listed at https://docs.monai.io/en/latest/networks.html#nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "We've covered MONAI Datasets, Caching and Networks.  Here are some key highlights:\n",
    "\n",
    "- A MONAI Dataset is a generic dataset with a len property, getitem property, and an optional callable data transform when fetching a data sample.\n",
    "- You can use dataset caching to store dataset transforms to speed up training.  Some included Caching options are CachingDataset, PersistentCaching, and SmartCaching\n",
    "- MONAI provides access to some commonly used medical imaging datasets including the DecathlonDataset\n",
    "- Understanding the basic MONAI Layers\n",
    "- Use MONAI layers to implement a flexible network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Next Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next notebook, we cover MONAI Sliding Inference and Post-Processing Transforms.\n",
    "\n",
    "You can find more information about everything covered here on our [MONAI Documentation Page](https://docs.monai.io/).  \n",
    "\n",
    "If you're looking for more examples and tutorials, we have a repo dedicated just to that!  You can find it on our [GitHub Organization Page](https://github.com/Project-MONAI/tutorials).  We also have all of our videos from our first ever MONAI Bootcamp available on our [Youtube Channel](https://www.youtube.com/c/ProjectMONAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
